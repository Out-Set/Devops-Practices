input {
  # --- Read from PostgreSQL ---
  jdbc {
    jdbc_driver_library => "/db-lib/postgresql-42.7.3.jar"
    jdbc_driver_class => "org.postgresql.Driver"
    jdbc_connection_string => "jdbc:postgresql://host.docker.internal:5432/aims"
    jdbc_user => "postgres"
    jdbc_password => "12345"
    statement => "select code, host, name, order_number, test_name, value, value_type, patient_id from test_detail"
    schedule => "0/30 * * * * *"  # every 30 seconds
    type => "jdbc_source"
  }

  # --- Read from Kafka ---
  kafka {
    bootstrap_servers => "172.16.130.124:9092"
    topics => ["lab"]
    group_id => "AIMS"
    codec => json
    type => "kafka_source"
  }
}

filter {
  # Optional: add source metadata field to distinguish events
  mutate {
    add_field => { "source_type" => "%{type}" }
  }
}

output {
  # --- Send all data to OpenSearch ---
  opensearch {
    hosts => ["https://opensearch-node:9200"]
    index => "lab_tests"
    user => "admin"
    password => "@qazxsW$345#"
    ssl => true
    ssl_certificate_verification => false
    manage_template => false
  }

  # Optional: debug to stdout
  stdout {
    codec => rubydebug
  }
}